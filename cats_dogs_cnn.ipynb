{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and pre-processing the images\n",
    "DATADIR = \"Datasets/PetImages\"\n",
    "CATEGORIES = [\"Cat\", \"Dog\"]\n",
    "\n",
    "training_data = []\n",
    "IMG_SIZE = 70\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img))\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomizing the data\n",
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out different combinations of layers\n",
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [64, 128, 256]\n",
    "conv_layers = [1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = f'dense{dense_layer}-layer_size{layer_size}-conv_layer{conv_layer}-{int(time.time())}'\n",
    "            tensorboard = TensorBoard(log_dir=f'logs/{NAME}')\n",
    "            \n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3,3), activation=\"relu\", input_shape = X.shape[1:]))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "            for l in range(conv_layer - 1):\n",
    "                model.add(Conv2D(layer_size, (3,3), activation=\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation= \"relu\"))\n",
    "                model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "            model.compile(loss=\"binary_crossentropy\", \n",
    "                            optimizer=\"adam\", \n",
    "                            metrics=[\"accuracy\"])\n",
    "\n",
    "            model.fit(X, y, batch_size=32, \n",
    "                            epochs=10, \n",
    "                            validation_split=0.3,\n",
    "                            callbacks= [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 20:45:33.894673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 20:45:33.921290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 20:45:33.921491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 20:45:33.921866: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-27 20:45:33.922578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 20:45:33.922742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 20:45:33.922887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 20:45:34.261387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 20:45:34.261571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 20:45:34.261724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 20:45:34.261852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5\n",
      "2022-04-27 20:45:34.262051: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 20:45:35.739041: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546/546 [==============================] - 6s 8ms/step - loss: 0.6141 - accuracy: 0.6520 - val_loss: 0.5286 - val_accuracy: 0.7340\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 0.5068 - accuracy: 0.7534 - val_loss: 0.4605 - val_accuracy: 0.7795\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 0.4395 - accuracy: 0.7954 - val_loss: 0.4227 - val_accuracy: 0.8059\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 0.3828 - accuracy: 0.8292 - val_loss: 0.3778 - val_accuracy: 0.8282\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 0.3355 - accuracy: 0.8514 - val_loss: 0.3653 - val_accuracy: 0.8390\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 0.2942 - accuracy: 0.8722 - val_loss: 0.3703 - val_accuracy: 0.8369\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 0.2546 - accuracy: 0.8943 - val_loss: 0.3761 - val_accuracy: 0.8426\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 0.2217 - accuracy: 0.9064 - val_loss: 0.3953 - val_accuracy: 0.8335\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 0.1865 - accuracy: 0.9242 - val_loss: 0.3804 - val_accuracy: 0.8561\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 0.1479 - accuracy: 0.9423 - val_loss: 0.4046 - val_accuracy: 0.8532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9614706170>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best combination for accuracy: 85% achieved\n",
    "#Convolutional layers=3, Dense layers=1, Layer size = 64\n",
    "\n",
    "NAME = f'dense1-layer_size64-conv_layer3-{int(time.time())}'\n",
    "tensorboard = TensorBoard(log_dir=f'logs/{NAME}')\n",
    "            \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\", input_shape = X.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\",)) \n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation= \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", \n",
    "                optimizer=\"adam\", \n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X, y, batch_size=32, \n",
    "                epochs=10, \n",
    "                validation_split=0.3,\n",
    "                callbacks= [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making custom predictions\n",
    "def make_prediction(test_img):\n",
    "    t_img = cv2.imread(test_img)\n",
    "    t_img_rz = cv2.resize(t_img, (IMG_SIZE, IMG_SIZE))\n",
    "    t_img_rs = t_img_rz.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "    result = model.predict(t_img_rs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
