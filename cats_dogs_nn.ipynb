{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 399 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "#Importing and pre-processing the images\n",
    "DATADIR = \"Datasets/PetImages\"\n",
    "CATEGORIES = [\"Cat\", \"Dog\"]\n",
    "\n",
    "training_data = []\n",
    "IMG_SIZE = 70\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img))\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomizing the data\n",
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y = np.array(y).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[5000:], X[:5000]\n",
    "y_train, y_test = y[5000:], y[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out different combinations of layers\n",
    "dense_layers = [1,2]\n",
    "layer_sizes = [64, 128, 256]\n",
    "conv_layers = [1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = f'dense{dense_layer}-layer_size{layer_size}-conv_layer{conv_layer}-{int(time.time())}'\n",
    "            tensorboard = TensorBoard(log_dir=f'logs/{NAME}')\n",
    "            \n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3,3), activation=\"relu\", input_shape = X_train.shape[1:]))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "            for l in range(conv_layer - 1):\n",
    "                model.add(Conv2D(layer_size, (3,3), activation=\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation= \"relu\"))\n",
    "                model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "            model.compile(loss=\"binary_crossentropy\", \n",
    "                            optimizer=\"adam\", \n",
    "                            metrics=[\"accuracy\"])\n",
    "\n",
    "            model.fit(X_train, y_train, batch_size=32, \n",
    "                            epochs=10, \n",
    "                            validation_data=(X_test, y_test),\n",
    "                            callbacks= [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:36:33.544770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 13:36:33.570814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 13:36:33.571014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 13:36:33.571340: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-28 13:36:33.572105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 13:36:33.572269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 13:36:33.572413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 13:36:33.884130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 13:36:33.884317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 13:36:33.884467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 13:36:33.884593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6382 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5\n",
      "2022-04-28 13:36:33.884772: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:36:35.533194: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 6s 7ms/step - loss: 0.6257 - accuracy: 0.6377 - val_loss: 0.5563 - val_accuracy: 0.7270\n",
      "Epoch 2/10\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.5173 - accuracy: 0.7464 - val_loss: 0.4943 - val_accuracy: 0.7678\n",
      "Epoch 3/10\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.4368 - accuracy: 0.7989 - val_loss: 0.4096 - val_accuracy: 0.8124\n",
      "Epoch 4/10\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.3859 - accuracy: 0.8260 - val_loss: 0.3902 - val_accuracy: 0.8204\n",
      "Epoch 5/10\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.3387 - accuracy: 0.8500 - val_loss: 0.3799 - val_accuracy: 0.8312\n",
      "Epoch 6/10\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.2974 - accuracy: 0.8742 - val_loss: 0.3417 - val_accuracy: 0.8502\n",
      "Epoch 7/10\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.2485 - accuracy: 0.8955 - val_loss: 0.3636 - val_accuracy: 0.8450\n",
      "Epoch 8/10\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.2135 - accuracy: 0.9113 - val_loss: 0.3979 - val_accuracy: 0.8422\n",
      "Epoch 9/10\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.1809 - accuracy: 0.9252 - val_loss: 0.3622 - val_accuracy: 0.8444\n",
      "Epoch 10/10\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.1485 - accuracy: 0.9413 - val_loss: 0.4095 - val_accuracy: 0.8572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01583b0bb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best combination for accuracy: 85% achieved\n",
    "#Convolutional layers=3, Dense layers=1, Layer size = 64\n",
    "\n",
    "NAME = f'dense1-layer_size64-conv_layer3-{int(time.time())}'\n",
    "tensorboard = TensorBoard(log_dir=f'logs/{NAME}')\n",
    "            \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\", input_shape = X_train.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\",)) \n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation= \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", \n",
    "                optimizer=\"adam\", \n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, \n",
    "                epochs=10, \n",
    "                validation_data=(X_test,y_test),\n",
    "                callbacks= [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.8572\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      2420\n",
      "           1       0.87      0.85      0.86      2580\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[2081  375]\n",
      " [ 339 2205]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted= (y_predicted>0.5)\n",
    "\n",
    "#Tests to check if used model is good\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "print(f'Accuracy score is {accuracy_score(y_test, y_predicted)}')\n",
    "print(f'\\nClassification report:\\n{classification_report(y_test, y_predicted)}')\n",
    "print(f'\\nConfusion matrix:\\n{confusion_matrix(y_predicted, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making custom predictions\n",
    "def make_prediction(test_img):\n",
    "    t_img = cv2.imread(test_img)\n",
    "    t_img_rz = cv2.resize(t_img, (IMG_SIZE, IMG_SIZE))\n",
    "    t_img_rs = t_img_rz.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "    result = model.predict(t_img_rs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "pred = make_prediction('dog2.jpg')\n",
    "print(CATEGORIES[int(pred[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
